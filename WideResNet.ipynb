{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOhbp8M4HKJdaHnc1ZXAXvP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwarang97/paperswithcode/blob/main/WideResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3bPuzTuGTtWn",
        "outputId": "d8adb177-dde3-433e-f65a-6510f915fb5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Basic_Block(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.stride = stride\n",
        "        self.residual = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels), # pre_activation part\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "        # self.relu = nn.ReLU() # tranfer relu to reisual part\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.residual(x)\n",
        "        if self.in_channels != self.out_channels or self.stride!=1:\n",
        "            identity = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, self.out_channels, kernel_size=1, stride=self.stride, padding=1, bias=False)\n",
        "                # nn.BatchNorm2d(self.out_channels) # According to pre-activation papaer, because of overlapping BN, remove BN\n",
        "            )\n",
        "            shortcut = identity(x)\n",
        "        else:\n",
        "            shortcut = x\n",
        "        # return self.relu(residual+shortcut)\n",
        "        return residual+shortcut\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.expansion = 4\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.stride = stride\n",
        "        self.residual = nn.Sequential(\n",
        "            nn.BatchNorm2d(in_channels), # pre-activation part(BN, ReLU)\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(self.expansion * out_channels),\n",
        "        )\n",
        "        # self.relu = nn.ReLU() # transfer to resiual part\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.residual(x)\n",
        "        if self.in_channels != self.expansion * self.out_channels or self.stride!=1:\n",
        "            identity = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, self.expansion * self.out_channels, kernel_size=1, stride=self.stride, padding=1, bias=False)\n",
        "                # nn.BatchNorm2d(self.out_channels)\n",
        "            )\n",
        "            shortcut = identity(x)\n",
        "        else:\n",
        "            shortcut = x\n",
        "        # return self.relu(residual+shortcut)\n",
        "        return residual+shortcut\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_layers, num_class=1000):\n",
        "        super().__init__()\n",
        "        self.channels = 64\n",
        "\n",
        "        self.conv_1 = nn.Conv2d(3, 64, kernel_size=7, stride=2)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv_2 = nn.Sequential(\n",
        "            *self.make_layer(num_layers[0], self.channels, self.channels, block, stride=1)\n",
        "        )\n",
        "        self.conv_3 = nn.Sequential(\n",
        "            *self.make_layer(num_layers[1], block.expansion*self.channels, 2*self.channels, block,stride=2)\n",
        "        )\n",
        "        self.conv_4 = nn.Sequential(\n",
        "            *self.make_layer(num_layers[2], 2*block.expansion*self.channels, 4*self.channels, block,stride=2)\n",
        "        )\n",
        "        self.conv_5 = nn.Sequential(\n",
        "            *self.make_layer(num_layers[3], 4*block.expansion*self.channels, 8*self.channels, block,stride=2)\n",
        "        )\n",
        "        self.gap = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(block.expansion*8*self.channels, num_class)\n",
        "\n",
        "    def make_layer(self, num, in_channels, out_channels, block, stride):\n",
        "        layer = []\n",
        "        if in_channels != block.expansion *out_channels or stride!=1:\n",
        "            layer.append(nn.Conv2d(in_channels, block.expansion*out_channels, kernel_size=1, stride=stride, padding=0))\n",
        "            for _ in range(num-1):\n",
        "                layer.append(block(block.expansion*out_channels, out_channels))\n",
        "        else:\n",
        "            for _ in range(num):\n",
        "                layer.append(block(block.expansion*out_channels, out_channels))\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.conv_4(x)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2D-Ks0kkrzjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18(**kwargs):\n",
        "    return ResNet(Basic_Block, [2, 2, 2, 2], **kwargs)\n",
        "\n",
        "def resnet34(**kwargs):\n",
        "    return ResNet(Basic_Block, [3, 4, 6, 3], **kwargs)\n",
        "\n",
        "def resnet50(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "\n",
        "def resnet101(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "\n",
        "def resnet152(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)"
      ],
      "metadata": {
        "id": "qD1YYpYHU5n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet152()\n",
        "model.train()\n",
        "summary(model, input_size=(10,3,224,244), device='cpu') # 기본적으로 gpu에 입력값을 생성하기에, cpu로 변경시켜줘야함."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjvMFSSHVIN2",
        "outputId": "fb2971e6-dc1b-46b5-ceed-77fcc45075e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet                                   [10, 1000]                --\n",
              "├─Conv2d: 1-1                            [10, 64, 109, 119]        9,472\n",
              "├─MaxPool2d: 1-2                         [10, 64, 54, 59]          --\n",
              "├─Sequential: 1-3                        [10, 256, 54, 59]         --\n",
              "│    └─Conv2d: 2-1                       [10, 256, 54, 59]         16,640\n",
              "│    └─Bottleneck: 2-2                   [10, 256, 54, 59]         --\n",
              "│    │    └─Sequential: 3-1              [10, 256, 54, 59]         70,912\n",
              "│    └─Bottleneck: 2-3                   [10, 256, 54, 59]         --\n",
              "│    │    └─Sequential: 3-2              [10, 256, 54, 59]         70,912\n",
              "├─Sequential: 1-4                        [10, 512, 27, 30]         --\n",
              "│    └─Conv2d: 2-4                       [10, 512, 27, 30]         131,584\n",
              "│    └─Bottleneck: 2-5                   [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-3              [10, 512, 27, 30]         281,088\n",
              "│    └─Bottleneck: 2-6                   [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-4              [10, 512, 27, 30]         281,088\n",
              "│    └─Bottleneck: 2-7                   [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-5              [10, 512, 27, 30]         281,088\n",
              "│    └─Bottleneck: 2-8                   [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-6              [10, 512, 27, 30]         281,088\n",
              "│    └─Bottleneck: 2-9                   [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-7              [10, 512, 27, 30]         281,088\n",
              "│    └─Bottleneck: 2-10                  [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-8              [10, 512, 27, 30]         281,088\n",
              "│    └─Bottleneck: 2-11                  [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-9              [10, 512, 27, 30]         281,088\n",
              "├─Sequential: 1-5                        [10, 1024, 14, 15]        --\n",
              "│    └─Conv2d: 2-12                      [10, 1024, 14, 15]        525,312\n",
              "│    └─Bottleneck: 2-13                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-10             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-14                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-11             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-15                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-12             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-16                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-13             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-17                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-14             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-18                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-15             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-19                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-16             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-20                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-17             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-21                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-18             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-22                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-19             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-23                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-20             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-24                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-21             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-25                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-22             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-26                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-23             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-27                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-24             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-28                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-25             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-29                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-26             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-30                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-27             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-31                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-28             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-32                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-29             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-33                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-30             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-34                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-31             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-35                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-32             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-36                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-33             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-37                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-34             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-38                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-35             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-39                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-36             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-40                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-37             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-41                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-38             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-42                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-39             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-43                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-40             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-44                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-41             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-45                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-42             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-46                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-43             [10, 1024, 14, 15]        1,119,232\n",
              "│    └─Bottleneck: 2-47                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-44             [10, 1024, 14, 15]        1,119,232\n",
              "├─Sequential: 1-6                        [10, 2048, 7, 8]          --\n",
              "│    └─Conv2d: 2-48                      [10, 2048, 7, 8]          2,099,200\n",
              "│    └─Bottleneck: 2-49                  [10, 2048, 7, 8]          --\n",
              "│    │    └─Sequential: 3-45             [10, 2048, 7, 8]          4,466,688\n",
              "│    └─Bottleneck: 2-50                  [10, 2048, 7, 8]          --\n",
              "│    │    └─Sequential: 3-46             [10, 2048, 7, 8]          4,466,688\n",
              "├─AvgPool2d: 1-7                         [10, 2048, 1, 1]          --\n",
              "├─Linear: 1-8                            [10, 1000]                2,049,000\n",
              "==========================================================================================\n",
              "Total params: 55,047,144\n",
              "Trainable params: 55,047,144\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 112.23\n",
              "==========================================================================================\n",
              "Input size (MB): 6.56\n",
              "Forward/backward pass size (MB): 4124.11\n",
              "Params size (MB): 220.19\n",
              "Estimated Total Size (MB): 4350.86\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}