{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyPyYg5/YiZG+ngroo1pLDJf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwarang97/paperswithcode/blob/main/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nugdvnAvrFZx",
        "outputId": "51e8dffb-aa98-4d47-dae1-9127279ac82b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def select_model(depth):\n",
        "    if depth == 18:\n",
        "        return ResNet_18()\n",
        "\n",
        "    elif depth == 34:\n",
        "        return ResNet_34()\n",
        "\n",
        "    elif depth == 50:\n",
        "        return ResNet_50()\n",
        "\n",
        "    elif depth == 101:\n",
        "        return ResNet_101()\n",
        "\n",
        "    elif depth == 152:\n",
        "        return ResNet_152()\n",
        "\n",
        "    else:\n",
        "        print(f'check if model depth is in {[18, 34, 50, 101, 152]}')"
      ],
      "metadata": {
        "id": "-Bgn4hJiPBNf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "class Identity_Block(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            BasicConv2d(in_channels, in_channels),\n",
        "            BasicConv2d(in_channels, in_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "class Identity_Block_L(nn.Module):\n",
        "    def __init__(self, in_channels, ratio):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            BasicConv2d(in_channels, int(ratio*in_channels), kernel_size=1, padding=0), # 소수값이 들어가면 torch.empty() 함수에서 텐서를 생성할 때 에러 발생.\n",
        "            BasicConv2d(int(ratio*in_channels), int(ratio*in_channels)),\n",
        "            BasicConv2d(int(ratio*in_channels), 4*int(ratio*in_channels), kernel_size=1, padding=0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "class projection_Block(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            BasicConv2d(in_channels, 2*in_channels, stride=2),\n",
        "            BasicConv2d(2*in_channels, 2*in_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "class projection_Block_L(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            BasicConv2d(in_channels, int(0.5*in_channels), kernel_size=1, padding=0),\n",
        "            BasicConv2d(int(0.5*in_channels), int(0.5*in_channels), stride=2),\n",
        "            BasicConv2d(int(0.5*in_channels), 2*in_channels, kernel_size=1, padding=0)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "class ResNet_18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.channels = 64\n",
        "\n",
        "        self.conv_2 = nn.Sequential(\n",
        "            *self.make_layer(2, self.channels)\n",
        "        )\n",
        "        self.conv_3 = nn.Sequential(\n",
        "            projection_Block(self.channels),\n",
        "            *self.make_layer(1, 2*self.channels)\n",
        "        )\n",
        "        self.conv_4 = nn.Sequential(\n",
        "            projection_Block(2*self.channels),\n",
        "            *self.make_layer(1, 4*self.channels)\n",
        "        )\n",
        "        self.conv_5 = nn.Sequential(\n",
        "            projection_Block(4*self.channels),\n",
        "            *self.make_layer(1, 8*self.channels)\n",
        "        )\n",
        "        self.gap = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(8*self.channels,1000)\n",
        "\n",
        "    def make_layer(self, num, channels):\n",
        "        layer = []\n",
        "        for _ in range(num):\n",
        "            layer.append(Identity_Block(channels))\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.conv_4(x)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class ResNet_34(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.channels = 64\n",
        "\n",
        "        self.conv_2 = nn.Sequential(\n",
        "            *self.make_layer(3, self.channels)\n",
        "        )\n",
        "        self.conv_3 = nn.Sequential(\n",
        "            projection_Block(self.channels),\n",
        "            *self.make_layer(3, 2*self.channels)\n",
        "        )\n",
        "        self.conv_4 = nn.Sequential(\n",
        "            projection_Block(2*self.channels),\n",
        "            *self.make_layer(5, 4*self.channels)\n",
        "        )\n",
        "        self.conv_5 = nn.Sequential(\n",
        "            projection_Block(4*self.channels),\n",
        "            *self.make_layer(2, 8*self.channels)\n",
        "        )\n",
        "        self.gap = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(8*self.channels,1000)\n",
        "\n",
        "    def make_layer(self, num, channels, Block):\n",
        "        layer = []\n",
        "        for _ in range(num):\n",
        "            layer.append(Block(channels))\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.conv_4(x)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class ResNet_50(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.channels = 64\n",
        "\n",
        "        self.conv_2 = nn.Sequential(\n",
        "            Identity_Block_L(self.channels, 1),\n",
        "            *self.make_layer(2, 4*self.channels)\n",
        "        )\n",
        "        self.conv_3 = nn.Sequential(\n",
        "            projection_Block_L(4*self.channels),\n",
        "            *self.make_layer(3, 8*self.channels)\n",
        "        )\n",
        "        self.conv_4 = nn.Sequential(\n",
        "            projection_Block_L(8*self.channels),\n",
        "            *self.make_layer(5, 16*self.channels)\n",
        "        )\n",
        "        self.conv_5 = nn.Sequential(\n",
        "            projection_Block_L(16*self.channels),\n",
        "            *self.make_layer(2, 32*self.channels)\n",
        "        )\n",
        "        self.gap = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(32*self.channels,1000)\n",
        "\n",
        "    def make_layer(self, num, channels):\n",
        "        layer = []\n",
        "        for _ in range(num):\n",
        "            layer.append(Identity_Block_L(channels, 0.25))\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.conv_4(x)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class ResNet_101(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.channels = 64\n",
        "\n",
        "        self.conv_2 = nn.Sequential(\n",
        "            Identity_Block_L(self.channels, 1),\n",
        "            *self.make_layer(2, 4*self.channels)\n",
        "        )\n",
        "        self.conv_3 = nn.Sequential(\n",
        "            projection_Block_L(4*self.channels),\n",
        "            *self.make_layer(3, 8*self.channels)\n",
        "        )\n",
        "        self.conv_4 = nn.Sequential(\n",
        "            projection_Block_L(8*self.channels),\n",
        "            *self.make_layer(22, 16*self.channels)\n",
        "        )\n",
        "        self.conv_5 = nn.Sequential(\n",
        "            projection_Block_L(16*self.channels),\n",
        "            *self.make_layer(2, 32*self.channels)\n",
        "        )\n",
        "        self.gap = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(32*self.channels,1000)\n",
        "\n",
        "    def make_layer(self, num, channels):\n",
        "        layer = []\n",
        "        for _ in range(num):\n",
        "            layer.append(Identity_Block_L(channels, 0.25))\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.conv_4(x)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class ResNet_152(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.channels = 64\n",
        "\n",
        "        self.conv_2 = nn.Sequential(\n",
        "            Identity_Block_L(self.channels, 1),\n",
        "            *self.make_layer(2, 4*self.channels)\n",
        "        )\n",
        "        self.conv_3 = nn.Sequential(\n",
        "            projection_Block_L(4*self.channels),\n",
        "            *self.make_layer(7, 8*self.channels)\n",
        "        )\n",
        "        self.conv_4 = nn.Sequential(\n",
        "            projection_Block_L(8*self.channels),\n",
        "            *self.make_layer(35, 16*self.channels)\n",
        "        )\n",
        "        self.conv_5 = nn.Sequential(\n",
        "            projection_Block_L(16*self.channels),\n",
        "            *self.make_layer(2, 32*self.channels)\n",
        "        )\n",
        "        self.gap = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(32*self.channels,1000)\n",
        "\n",
        "    def make_layer(self, num, channels):\n",
        "        layer = []\n",
        "        for _ in range(num):\n",
        "            layer.append(Identity_Block_L(channels, 0.25))\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.conv_4(x)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2D-Ks0kkrzjp"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depth = 152 # [18, 34, 50, 101, 152]\n",
        "model = select_model(depth)\n",
        "model.train()\n",
        "\n",
        "summary(model, input_size=(10,64,56,56))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZmKr9Sv5Vi8",
        "outputId": "2dec4a4b-665c-47ef-a3b8-6ee462decb54"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                             Output Shape              Param #\n",
              "====================================================================================================\n",
              "ResNet_152                                         [10, 1000]                --\n",
              "├─Sequential: 1-1                                  [10, 256, 56, 56]         --\n",
              "│    └─Identity_Block_L: 2-1                       [10, 256, 56, 56]         --\n",
              "│    │    └─Sequential: 3-1                        [10, 256, 56, 56]         58,112\n",
              "│    └─Identity_Block_L: 2-2                       [10, 256, 56, 56]         --\n",
              "│    │    └─Sequential: 3-2                        [10, 256, 56, 56]         70,400\n",
              "│    └─Identity_Block_L: 2-3                       [10, 256, 56, 56]         --\n",
              "│    │    └─Sequential: 3-3                        [10, 256, 56, 56]         70,400\n",
              "├─Sequential: 1-2                                  [10, 512, 28, 28]         --\n",
              "│    └─projection_Block_L: 2-4                     [10, 512, 28, 28]         --\n",
              "│    │    └─Sequential: 3-4                        [10, 512, 28, 28]         247,296\n",
              "│    └─Identity_Block_L: 2-5                       [10, 512, 28, 28]         --\n",
              "│    │    └─Sequential: 3-5                        [10, 512, 28, 28]         280,064\n",
              "│    └─Identity_Block_L: 2-6                       [10, 512, 28, 28]         --\n",
              "│    │    └─Sequential: 3-6                        [10, 512, 28, 28]         280,064\n",
              "│    └─Identity_Block_L: 2-7                       [10, 512, 28, 28]         --\n",
              "│    │    └─Sequential: 3-7                        [10, 512, 28, 28]         280,064\n",
              "│    └─Identity_Block_L: 2-8                       [10, 512, 28, 28]         --\n",
              "│    │    └─Sequential: 3-8                        [10, 512, 28, 28]         280,064\n",
              "│    └─Identity_Block_L: 2-9                       [10, 512, 28, 28]         --\n",
              "│    │    └─Sequential: 3-9                        [10, 512, 28, 28]         280,064\n",
              "│    └─Identity_Block_L: 2-10                      [10, 512, 28, 28]         --\n",
              "│    │    └─Sequential: 3-10                       [10, 512, 28, 28]         280,064\n",
              "│    └─Identity_Block_L: 2-11                      [10, 512, 28, 28]         --\n",
              "│    │    └─Sequential: 3-11                       [10, 512, 28, 28]         280,064\n",
              "├─Sequential: 1-3                                  [10, 1024, 14, 14]        --\n",
              "│    └─projection_Block_L: 2-12                    [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-12                       [10, 1024, 14, 14]        986,112\n",
              "│    └─Identity_Block_L: 2-13                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-13                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-14                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-14                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-15                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-15                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-16                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-16                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-17                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-17                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-18                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-18                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-19                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-19                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-20                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-20                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-21                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-21                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-22                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-22                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-23                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-23                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-24                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-24                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-25                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-25                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-26                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-26                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-27                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-27                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-28                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-28                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-29                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-29                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-30                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-30                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-31                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-31                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-32                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-32                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-33                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-33                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-34                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-34                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-35                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-35                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-36                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-36                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-37                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-37                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-38                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-38                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-39                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-39                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-40                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-40                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-41                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-41                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-42                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-42                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-43                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-43                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-44                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-44                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-45                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-45                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-46                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-46                       [10, 1024, 14, 14]        1,117,184\n",
              "│    └─Identity_Block_L: 2-47                      [10, 1024, 14, 14]        --\n",
              "│    │    └─Sequential: 3-47                       [10, 1024, 14, 14]        1,117,184\n",
              "├─Sequential: 1-4                                  [10, 2048, 7, 7]          --\n",
              "│    └─projection_Block_L: 2-48                    [10, 2048, 7, 7]          --\n",
              "│    │    └─Sequential: 3-48                       [10, 2048, 7, 7]          3,938,304\n",
              "│    └─Identity_Block_L: 2-49                      [10, 2048, 7, 7]          --\n",
              "│    │    └─Sequential: 3-49                       [10, 2048, 7, 7]          4,462,592\n",
              "│    └─Identity_Block_L: 2-50                      [10, 2048, 7, 7]          --\n",
              "│    │    └─Sequential: 3-50                       [10, 2048, 7, 7]          4,462,592\n",
              "├─AvgPool2d: 1-5                                   [10, 2048, 1, 1]          --\n",
              "├─Linear: 1-6                                      [10, 1000]                2,049,000\n",
              "====================================================================================================\n",
              "Total params: 57,406,696\n",
              "Trainable params: 57,406,696\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 110.36\n",
              "====================================================================================================\n",
              "Input size (MB): 8.03\n",
              "Forward/backward pass size (MB): 3239.44\n",
              "Params size (MB): 229.63\n",
              "Estimated Total Size (MB): 3477.10\n",
              "===================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ]
}