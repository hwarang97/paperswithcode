{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyOaT47gmdB/+J98PTC1bT+1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwarang97/paperswithcode/blob/main/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nugdvnAvrFZx",
        "outputId": "bb0ecdc6-a48c-45e1-db60-de2004d1dc69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Basic_Block(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.stride = stride\n",
        "        self.residual = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.residual(x)\n",
        "        if self.in_channels != self.out_channels or self.stride!=1:\n",
        "            identity = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, self.out_channels, kernel_size=1, stride=self.stride, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(self.out_channels)\n",
        "            )\n",
        "            shortcut = identity(x)\n",
        "        else:\n",
        "            shortcut = x\n",
        "        return self.relu(residual+shortcut)\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.expansion = 4\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.stride = stride\n",
        "        self.residual = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(self.expansion * out_channels),\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.residual(x)\n",
        "        if self.in_channels != self.expansion * self.out_channels or self.stride!=1:\n",
        "            identity = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, self.expansion * self.out_channels, kernel_size=1, stride=self.stride, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(self.out_channels)\n",
        "            )\n",
        "            shortcut = identity(x)\n",
        "        else:\n",
        "            shortcut = x\n",
        "        return self.relu(residual+shortcut)\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_layers, num_class=1000):\n",
        "        super().__init__()\n",
        "        self.channels = 64\n",
        "\n",
        "        self.conv_1 = nn.Conv2d(3, 64, kernel_size=7, stride=2)\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "        self.conv_2 = nn.Sequential(\n",
        "            *self.make_layer(num_layers[0], self.channels, self.channels, block, stride=1)\n",
        "        )\n",
        "        self.conv_3 = nn.Sequential(\n",
        "            *self.make_layer(num_layers[1], block.expansion*self.channels, 2*self.channels, block,stride=2)\n",
        "        )\n",
        "        self.conv_4 = nn.Sequential(\n",
        "            *self.make_layer(num_layers[2], 2*block.expansion*self.channels, 4*self.channels, block,stride=2)\n",
        "        )\n",
        "        self.conv_5 = nn.Sequential(\n",
        "            *self.make_layer(num_layers[3], 4*block.expansion*self.channels, 8*self.channels, block,stride=2)\n",
        "        )\n",
        "        self.gap = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(block.expansion*8*self.channels, num_class)\n",
        "\n",
        "    def make_layer(self, num, in_channels, out_channels, block, stride):\n",
        "        layer = []\n",
        "        if in_channels != block.expansion *out_channels or stride!=1:\n",
        "            layer.append(nn.Conv2d(in_channels, block.expansion*out_channels, kernel_size=1, stride=stride, padding=0))\n",
        "            for _ in range(num-1):\n",
        "                layer.append(block(block.expansion*out_channels, out_channels))\n",
        "        else:\n",
        "            for _ in range(num):\n",
        "                layer.append(block(block.expansion*out_channels, out_channels))\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_1(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.conv_4(x)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# class ResNet_18(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.channels = 64\n",
        "\n",
        "#         self.conv_2 = nn.Sequential(\n",
        "#             *self.make_layer(2, self.channels, self.channels, stride=1)\n",
        "#         )\n",
        "#         self.conv_3 = nn.Sequential(\n",
        "#             *self.make_layer(2, self.channels, 2*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.conv_4 = nn.Sequential(\n",
        "#             *self.make_layer(2, 2*self.channels, 4*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.conv_5 = nn.Sequential(\n",
        "#             *self.make_layer(2, 4*self.channels, 8*self.channels, stride=2)\n",
        "\n",
        "#         )\n",
        "#         self.gap = nn.AvgPool2d(7)\n",
        "#         self.fc = nn.Linear(8*self.channels,1000)\n",
        "\n",
        "#     def make_layer(self, num, in_channels, out_channels, stride):\n",
        "#         layer = []\n",
        "#         if in_channels != out_channels or stride!=1:\n",
        "#             layer.append(Basic_Block(in_channels, out_channels, kernel_size=1, stride=stride))\n",
        "#             for _ in range(num-1):\n",
        "#                 layer.append(Basic_Block(out_channels, out_channels))\n",
        "#         else:\n",
        "#             for _ in range(num):\n",
        "#                 layer.append(Basic_Block(in_channels, in_channels))\n",
        "#         return layer\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv_2(x)\n",
        "#         x = self.conv_3(x)\n",
        "#         x = self.conv_4(x)\n",
        "#         x = self.conv_5(x)\n",
        "#         x = self.gap(x)\n",
        "#         x = torch.flatten(x, start_dim=1)\n",
        "#         x = self.fc(x)\n",
        "#         return x\n",
        "\n",
        "# class ResNet_34(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.channels = 64\n",
        "\n",
        "#         self.conv_2 = nn.Sequential(\n",
        "#             *self.make_layer(3, self.channels, self.channels, stride=1)\n",
        "#         )\n",
        "#         self.conv_3 = nn.Sequential(\n",
        "#             *self.make_layer(4, self.channels, 2*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.conv_4 = nn.Sequential(\n",
        "#             *self.make_layer(6, 2*self.channels, 4*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.conv_5 = nn.Sequential(\n",
        "#             *self.make_layer(3, 4*self.channels, 8*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.gap = nn.AvgPool2d(7)\n",
        "#         self.fc = nn.Linear(8*self.channels,1000)\n",
        "\n",
        "#     def make_layer(self, num, in_channels, out_channels, stride):\n",
        "#         layer = []\n",
        "#         if in_channels != out_channels or stride!=1:\n",
        "#             layer.append(Basic_Block(in_channels, out_channels, kernel_size=1, stride=stride))\n",
        "#             for _ in range(num-1):\n",
        "#                 layer.append(Basic_Block(out_channels, out_channels))\n",
        "#         else:\n",
        "#             for _ in range(num):\n",
        "#                 layer.append(Basic_Block(in_channels, out_channels))\n",
        "#         return layer\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv_2(x)\n",
        "#         x = self.conv_3(x)\n",
        "#         x = self.conv_4(x)\n",
        "#         x = self.conv_5(x)\n",
        "#         x = self.gap(x)\n",
        "#         x = torch.flatten(x, start_dim=1)\n",
        "#         x = self.fc(x)\n",
        "#         return x\n",
        "\n",
        "# class ResNet_50(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.channels = 64\n",
        "#         self.expansion = 4\n",
        "\n",
        "#         self.conv_2 = nn.Sequential(\n",
        "#             *self.make_layer(3, self.channels, self.channels, stride=1)\n",
        "#         )\n",
        "#         self.conv_3 = nn.Sequential(\n",
        "#             *self.make_layer(4, 4*self.channels, 2*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.conv_4 = nn.Sequential(\n",
        "#             *self.make_layer(6, 8*self.channels, 4*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.conv_5 = nn.Sequential(\n",
        "#             *self.make_layer(3, 16*self.channels, 8*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.gap = nn.AvgPool2d(7)\n",
        "#         self.fc = nn.Linear(32*self.channels,1000)\n",
        "\n",
        "#     def make_layer(self, num, in_channels, out_channels, stride):\n",
        "#         layer = []\n",
        "#         if in_channels != self.expansion *out_channels or stride!=1:\n",
        "#             layer.append(nn.Conv2d(in_channels, self.expansion*out_channels, kernel_size=1, stride=stride, padding=0))\n",
        "#             for _ in range(num-1):\n",
        "#                 layer.append(Bottleneck(self.expansion*out_channels, out_channels))\n",
        "#         else:\n",
        "#             for _ in range(num):\n",
        "#                 layer.append(Bottleneck(self.expansion*out_channels, out_channels))\n",
        "#         return layer\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv_2(x)\n",
        "#         x = self.conv_3(x)\n",
        "#         x = self.conv_4(x)\n",
        "#         x = self.conv_5(x)\n",
        "#         x = self.gap(x)\n",
        "#         x = torch.flatten(x, start_dim=1)\n",
        "#         x = self.fc(x)\n",
        "#         return x\n",
        "\n",
        "# class ResNet_101(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.channels = 64\n",
        "#         self.expansion = 4\n",
        "\n",
        "#         self.conv_2 = nn.Sequential(\n",
        "#             *self.make_layer(3, self.channels, self.channels, stride=1)\n",
        "#         )\n",
        "#         self.conv_3 = nn.Sequential(\n",
        "#             *self.make_layer(4, 4*self.channels, 2*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.conv_4 = nn.Sequential(\n",
        "#             *self.make_layer(23, 8*self.channels, 4*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.conv_5 = nn.Sequential(\n",
        "#             *self.make_layer(3, 16*self.channels, 8*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.gap = nn.AvgPool2d(7)\n",
        "#         self.fc = nn.Linear(32*self.channels,1000)\n",
        "\n",
        "#     def make_layer(self, num, in_channels, out_channels, stride):\n",
        "#         layer = []\n",
        "#         if in_channels != self.expansion *out_channels or stride!=1:\n",
        "#             layer.append(nn.Conv2d(in_channels, self.expansion*out_channels, kernel_size=1, stride=stride, padding=0))\n",
        "#             for _ in range(num-1):\n",
        "#                 layer.append(Bottleneck(self.expansion*out_channels, out_channels))\n",
        "#         else:\n",
        "#             for _ in range(num):\n",
        "#                 layer.append(Bottleneck(self.expansion*out_channels, out_channels))\n",
        "#         return layer\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv_2(x)\n",
        "#         x = self.conv_3(x)\n",
        "#         x = self.conv_4(x)\n",
        "#         x = self.conv_5(x)\n",
        "#         x = self.gap(x)\n",
        "#         x = torch.flatten(x, start_dim=1)\n",
        "#         x = self.fc(x)\n",
        "#         return x\n",
        "\n",
        "# class ResNet_152(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.channels = 64\n",
        "#         self.expansion = 4\n",
        "\n",
        "#         self.conv_2 = nn.Sequential(\n",
        "#             *self.make_layer(3, self.channels, self.channels, stride=1)\n",
        "#         )\n",
        "#         self.conv_3 = nn.Sequential(\n",
        "#             *self.make_layer(8, 4*self.channels, 2*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.conv_4 = nn.Sequential(\n",
        "#             *self.make_layer(36, 8*self.channels, 4*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.conv_5 = nn.Sequential(\n",
        "#             *self.make_layer(3, 16*self.channels, 8*self.channels, stride=2)\n",
        "#         )\n",
        "#         self.gap = nn.AvgPool2d(7)\n",
        "#         self.fc = nn.Linear(32*self.channels,1000)\n",
        "\n",
        "#     def make_layer(self, num, in_channels, out_channels, stride):\n",
        "#         layer = []\n",
        "#         if in_channels != self.expansion *out_channels or stride!=1:\n",
        "#             layer.append(nn.Conv2d(in_channels, self.expansion*out_channels, kernel_size=1, stride=stride, padding=0))\n",
        "#             for _ in range(num-1):\n",
        "#                 layer.append(Bottleneck(self.expansion*out_channels, out_channels))\n",
        "#         else:\n",
        "#             for _ in range(num):\n",
        "#                 layer.append(Bottleneck(self.expansion*out_channels, out_channels))\n",
        "#         return layer\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv_2(x)\n",
        "#         x = self.conv_3(x)\n",
        "#         x = self.conv_4(x)\n",
        "#         x = self.conv_5(x)\n",
        "#         x = self.gap(x)\n",
        "#         x = torch.flatten(x, start_dim=1)\n",
        "#         x = self.fc(x)\n",
        "#         return x\n",
        "\n"
      ],
      "metadata": {
        "id": "2D-Ks0kkrzjp"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18(**kwargs):\n",
        "    return ResNet(Basic_Block, [2, 2, 2, 2], **kwargs)\n",
        "\n",
        "def resnet34(**kwargs):\n",
        "    return ResNet(Basic_Block, [3, 4, 6, 3], **kwargs)\n",
        "\n",
        "def resnet50(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "\n",
        "def resnet101(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "\n",
        "def resnet152(**kwargs):\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)"
      ],
      "metadata": {
        "id": "-Q39uYdr1J3U"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = resnet152()\n",
        "model.train()\n",
        "summary(model, input_size=(10,3,224,244), device='cpu') # 기본적으로 gpu에 입력값을 생성하기에, cpu로 변경시켜줘야함."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "la0HnxA-1Z_W",
        "outputId": "233feaa8-03eb-4ba9-9d08-568e11ca7c1f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "ResNet                                   [10, 1000]                --\n",
              "├─Conv2d: 1-1                            [10, 64, 109, 119]        9,472\n",
              "├─MaxPool2d: 1-2                         [10, 64, 54, 59]          --\n",
              "├─Sequential: 1-3                        [10, 256, 54, 59]         --\n",
              "│    └─Conv2d: 2-1                       [10, 256, 54, 59]         16,640\n",
              "│    └─Bottleneck: 2-2                   [10, 256, 54, 59]         --\n",
              "│    │    └─Sequential: 3-1              [10, 256, 54, 59]         70,400\n",
              "│    │    └─ReLU: 3-2                    [10, 256, 54, 59]         --\n",
              "│    └─Bottleneck: 2-3                   [10, 256, 54, 59]         --\n",
              "│    │    └─Sequential: 3-3              [10, 256, 54, 59]         70,400\n",
              "│    │    └─ReLU: 3-4                    [10, 256, 54, 59]         --\n",
              "├─Sequential: 1-4                        [10, 512, 27, 30]         --\n",
              "│    └─Conv2d: 2-4                       [10, 512, 27, 30]         131,584\n",
              "│    └─Bottleneck: 2-5                   [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-5              [10, 512, 27, 30]         280,064\n",
              "│    │    └─ReLU: 3-6                    [10, 512, 27, 30]         --\n",
              "│    └─Bottleneck: 2-6                   [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-7              [10, 512, 27, 30]         280,064\n",
              "│    │    └─ReLU: 3-8                    [10, 512, 27, 30]         --\n",
              "│    └─Bottleneck: 2-7                   [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-9              [10, 512, 27, 30]         280,064\n",
              "│    │    └─ReLU: 3-10                   [10, 512, 27, 30]         --\n",
              "│    └─Bottleneck: 2-8                   [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-11             [10, 512, 27, 30]         280,064\n",
              "│    │    └─ReLU: 3-12                   [10, 512, 27, 30]         --\n",
              "│    └─Bottleneck: 2-9                   [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-13             [10, 512, 27, 30]         280,064\n",
              "│    │    └─ReLU: 3-14                   [10, 512, 27, 30]         --\n",
              "│    └─Bottleneck: 2-10                  [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-15             [10, 512, 27, 30]         280,064\n",
              "│    │    └─ReLU: 3-16                   [10, 512, 27, 30]         --\n",
              "│    └─Bottleneck: 2-11                  [10, 512, 27, 30]         --\n",
              "│    │    └─Sequential: 3-17             [10, 512, 27, 30]         280,064\n",
              "│    │    └─ReLU: 3-18                   [10, 512, 27, 30]         --\n",
              "├─Sequential: 1-5                        [10, 1024, 14, 15]        --\n",
              "│    └─Conv2d: 2-12                      [10, 1024, 14, 15]        525,312\n",
              "│    └─Bottleneck: 2-13                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-19             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-20                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-14                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-21             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-22                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-15                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-23             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-24                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-16                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-25             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-26                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-17                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-27             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-28                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-18                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-29             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-30                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-19                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-31             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-32                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-20                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-33             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-34                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-21                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-35             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-36                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-22                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-37             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-38                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-23                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-39             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-40                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-24                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-41             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-42                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-25                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-43             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-44                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-26                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-45             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-46                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-27                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-47             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-48                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-28                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-49             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-50                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-29                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-51             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-52                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-30                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-53             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-54                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-31                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-55             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-56                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-32                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-57             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-58                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-33                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-59             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-60                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-34                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-61             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-62                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-35                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-63             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-64                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-36                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-65             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-66                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-37                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-67             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-68                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-38                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-69             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-70                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-39                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-71             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-72                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-40                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-73             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-74                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-41                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-75             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-76                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-42                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-77             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-78                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-43                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-79             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-80                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-44                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-81             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-82                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-45                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-83             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-84                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-46                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-85             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-86                   [10, 1024, 14, 15]        --\n",
              "│    └─Bottleneck: 2-47                  [10, 1024, 14, 15]        --\n",
              "│    │    └─Sequential: 3-87             [10, 1024, 14, 15]        1,117,184\n",
              "│    │    └─ReLU: 3-88                   [10, 1024, 14, 15]        --\n",
              "├─Sequential: 1-6                        [10, 2048, 7, 8]          --\n",
              "│    └─Conv2d: 2-48                      [10, 2048, 7, 8]          2,099,200\n",
              "│    └─Bottleneck: 2-49                  [10, 2048, 7, 8]          --\n",
              "│    │    └─Sequential: 3-89             [10, 2048, 7, 8]          4,462,592\n",
              "│    │    └─ReLU: 3-90                   [10, 2048, 7, 8]          --\n",
              "│    └─Bottleneck: 2-50                  [10, 2048, 7, 8]          --\n",
              "│    │    └─Sequential: 3-91             [10, 2048, 7, 8]          4,462,592\n",
              "│    │    └─ReLU: 3-92                   [10, 2048, 7, 8]          --\n",
              "├─AvgPool2d: 1-7                         [10, 2048, 1, 1]          --\n",
              "├─Linear: 1-8                            [10, 1000]                2,049,000\n",
              "==========================================================================================\n",
              "Total params: 54,959,080\n",
              "Trainable params: 54,959,080\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 112.23\n",
              "==========================================================================================\n",
              "Input size (MB): 6.56\n",
              "Forward/backward pass size (MB): 3140.91\n",
              "Params size (MB): 219.84\n",
              "Estimated Total Size (MB): 3367.30\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# error\n",
        "\n",
        "running_mean -> BN쪽에서 채널수를 잘 못맞출 경우 발생하는 에러 [에러 설명 사이트](https://stackoverflow.com/questions/72899079/what-do-batchnorm2ds-running-mean-running-var-mean-in-pytorch)"
      ],
      "metadata": {
        "id": "nEdzWSinwJ2Y"
      }
    }
  ]
}