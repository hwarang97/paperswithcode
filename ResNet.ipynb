{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNyQnU/pE8SVbQ0Ik/UghyD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwarang97/paperswithcode/blob/main/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nugdvnAvrFZx",
        "outputId": "8d0ccc79-4bd6-4fd1-bd52-b845b323eba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "!pip install torchinfo\n",
        "from torchinfo import summary\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def select_model(depth):\n",
        "    if depth == 18:\n",
        "        return ResNet_18()\n",
        "\n",
        "    elif depth == 34:\n",
        "        return ResNet_34()\n",
        "\n",
        "    elif depth == 50:\n",
        "        return ResNet_50()\n",
        "\n",
        "    elif depth == 101:\n",
        "        return ResNet_101()\n",
        "\n",
        "    elif depth == 152:\n",
        "        return ResNet_152()\n",
        "\n",
        "    else:\n",
        "        print(f'check if model depth is in {[18, 34, 50, 101, 152]}')"
      ],
      "metadata": {
        "id": "-Bgn4hJiPBNf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicConv2d(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "class Identity_Block(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            BasicConv2d(in_channels, in_channels),\n",
        "            BasicConv2d(in_channels, in_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "# class Identity_Block_L(nn.Module):\n",
        "#     def __init__(self, in_channels):\n",
        "#         super().__init__()\n",
        "#         self.block = nn.Sequential(\n",
        "#             BasicConv2d(in_channels, in_channels, kernel_size=1, padding=0),\n",
        "#             BasicConv2d(in_channels, in_channels),\n",
        "#             BasicConv2d(in_channels, 4*in_channels)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.block(x)\n",
        "#         return x\n",
        "\n",
        "class projection_Block(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            BasicConv2d(in_channels, 2*in_channels, stride=2),\n",
        "            # nn.Conv2d(in_channels, 2*in_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            # nn.BatchNorm2d(2*in_channels),\n",
        "            # nn.ReLU(),\n",
        "            BasicConv2d(2*in_channels, 2*in_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.block(x)\n",
        "        return x\n",
        "\n",
        "# class projection_Block(nn.Module):\n",
        "#     def __init__(self, in_channels):\n",
        "#         super().__init__()\n",
        "#         self.block = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels, 2*in_channels, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "#             nn.BatchNorm2d(2*in_channels),\n",
        "#             nn.ReLU(),\n",
        "#             BasicConv2d(2*in_channels, 2*in_channels)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.block(x)\n",
        "#         return x\n",
        "\n",
        "class ResNet_18(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.channels = 64\n",
        "\n",
        "        self.conv_2 = nn.Sequential(\n",
        "            *self.make_layer(2, self.channels)\n",
        "        )\n",
        "        self.conv_3 = nn.Sequential(\n",
        "            projection_Block(self.channels),\n",
        "            *self.make_layer(1, 2*self.channels)\n",
        "        )\n",
        "        self.conv_4 = nn.Sequential(\n",
        "            projection_Block(2*self.channels),\n",
        "            *self.make_layer(1, 4*self.channels)\n",
        "        )\n",
        "        self.conv_5 = nn.Sequential(\n",
        "            projection_Block(4*self.channels),\n",
        "            *self.make_layer(1, 8*self.channels)\n",
        "        )\n",
        "        self.gap = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(8*self.channels,1000)\n",
        "\n",
        "    def make_layer(self, num, channels):\n",
        "        layer = []\n",
        "        for _ in range(num):\n",
        "            layer.append(Identity_Block(channels))\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.conv_4(x)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class ResNet_34(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.channels = 64\n",
        "\n",
        "        self.conv_2 = nn.Sequential(\n",
        "            *self.make_layer(3, self.channels)\n",
        "        )\n",
        "        self.conv_3 = nn.Sequential(\n",
        "            projection_Block(self.channels),\n",
        "            *self.make_layer(3, 2*self.channels)\n",
        "        )\n",
        "        self.conv_4 = nn.Sequential(\n",
        "            projection_Block(2*self.channels),\n",
        "            *self.make_layer(5, 4*self.channels)\n",
        "        )\n",
        "        self.conv_5 = nn.Sequential(\n",
        "            projection_Block(4*self.channels),\n",
        "            *self.make_layer(2, 8*self.channels)\n",
        "        )\n",
        "        self.gap = nn.AvgPool2d(7)\n",
        "        self.fc = nn.Linear(8*self.channels,1000)\n",
        "\n",
        "    def make_layer(self, num, channels):\n",
        "        layer = []\n",
        "        for _ in range(num):\n",
        "            layer.append(Identity_Block(channels))\n",
        "        return layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        x = self.conv_4(x)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.gap(x)\n",
        "        x = torch.flatten(x, start_dim=1)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "2D-Ks0kkrzjp"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "depth = 18 # [18, 34, 50, 101, 152]\n",
        "model = select_model(depth)\n",
        "model.train()\n",
        "\n",
        "summary(model, input_size=(10,64,56,56))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZmKr9Sv5Vi8",
        "outputId": "e1e73ed3-8745-45d8-e09a-9b1d716dec60"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "====================================================================================================\n",
              "Layer (type:depth-idx)                             Output Shape              Param #\n",
              "====================================================================================================\n",
              "ResNet_18                                          [10, 1000]                --\n",
              "├─Sequential: 1-1                                  [10, 64, 56, 56]          --\n",
              "│    └─Identity_Block: 2-1                         [10, 64, 56, 56]          --\n",
              "│    │    └─Sequential: 3-1                        [10, 64, 56, 56]          73,984\n",
              "│    └─Identity_Block: 2-2                         [10, 64, 56, 56]          --\n",
              "│    │    └─Sequential: 3-2                        [10, 64, 56, 56]          73,984\n",
              "├─Sequential: 1-2                                  [10, 128, 28, 28]         --\n",
              "│    └─projection_Block: 2-3                       [10, 128, 28, 28]         --\n",
              "│    │    └─Sequential: 3-3                        [10, 128, 28, 28]         221,696\n",
              "│    └─Identity_Block: 2-4                         [10, 128, 28, 28]         --\n",
              "│    │    └─Sequential: 3-4                        [10, 128, 28, 28]         295,424\n",
              "├─Sequential: 1-3                                  [10, 256, 14, 14]         --\n",
              "│    └─projection_Block: 2-5                       [10, 256, 14, 14]         --\n",
              "│    │    └─Sequential: 3-5                        [10, 256, 14, 14]         885,760\n",
              "│    └─Identity_Block: 2-6                         [10, 256, 14, 14]         --\n",
              "│    │    └─Sequential: 3-6                        [10, 256, 14, 14]         1,180,672\n",
              "├─Sequential: 1-4                                  [10, 512, 7, 7]           --\n",
              "│    └─projection_Block: 2-7                       [10, 512, 7, 7]           --\n",
              "│    │    └─Sequential: 3-7                        [10, 512, 7, 7]           3,540,992\n",
              "│    └─Identity_Block: 2-8                         [10, 512, 7, 7]           --\n",
              "│    │    └─Sequential: 3-8                        [10, 512, 7, 7]           4,720,640\n",
              "├─AvgPool2d: 1-5                                   [10, 512, 1, 1]           --\n",
              "├─Linear: 1-6                                      [10, 1000]                513,000\n",
              "====================================================================================================\n",
              "Total params: 11,506,152\n",
              "Trainable params: 11,506,152\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 16.77\n",
              "====================================================================================================\n",
              "Input size (MB): 8.03\n",
              "Forward/backward pass size (MB): 240.92\n",
              "Params size (MB): 46.02\n",
              "Estimated Total Size (MB): 294.98\n",
              "===================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    }
  ]
}